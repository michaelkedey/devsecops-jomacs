name: Full Infrastructure + App Deploy + ELK Deploy

on:
  workflow_dispatch:
    inputs:
      action:
        description: "apply/destroy"
        required: true
        default: "apply"
        type: choice
        options:
          - apply
          - destroy

jobs:
  terraform-apply:
    if: ${{ github.event.inputs.action == 'apply' }}  
    name: "Terraform-apply"
    runs-on: ubuntu-latest
    outputs:
      bastion_ip: ${{ steps.tf_outputs.outputs.bastion_ip }}
      ec2_ip: ${{ steps.tf_outputs.outputs.ec2_ip }}
      elk_ip: ${{ steps.tf_outputs.outputs.elk_ip }}
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    defaults:
      run:
        working-directory: infra/aws/

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.1
          terraform_wrapper: false

      - name: Terraform Init
        run: terraform init

      - name: Terraform fmt
        run: terraform fmt -recursive

      - name: Terraform Plan
        run: terraform plan -no-color

      - name: Terraform Apply
        run: terraform apply -auto-approve
      
      - name: Capture Terraform Outputs
        id: tf_outputs
        run: |
          terraform output -json > outputs.json
          echo "Generated outputs.json at: $(pwd)/outputs.json"
              echo "--- outputs.json ---"
              cat outputs.json
              echo "--------------------"
          sudo apt-get install -y jq 
          echo "bastion_ip=$(jq -r '.bastion_public_ip.value' outputs.json)" >> $GITHUB_OUTPUT
          echo "ec2_ip=$(jq -r '.ec2_private_ip.value' outputs.json)" >> $GITHUB_OUTPUT
          echo "elk_ip=$(jq -r '.elk_private_ip.value' outputs.json)" >> $GITHUB_OUTPUT
          echo $bastion_ip

      - name: Upload Terraform Outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: infra/aws/outputs.json

  scan:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'apply' }}  
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2

      # 2. Set up Python environment and install dependencies
      - name: Set up Python 3.x
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ./app/python/requirements.txt
          pip install bandit safety

      # 3. Run Bandit scan (Python code security scanner)
      - name: Run Bandit Scan
        run: |
          pip install bandit
          bandit -r ./app/python -f json -o app/python/bandit-report.json || exit 1

      # 4. Run Safety scan (Dependency vulnerability scanner)
      - name: Run Safety Scan
        run: |
          pip install safety
          safety check -r app/python/requirements.txt --policy-file app/python/.safety.yaml --output json > app/python/safety-report.json || exit 1

      # 5. Upload the reports for later review
      - name: Upload Bandit Report
        if: always()  # Always upload, even if workflow fails
        uses: actions/upload-artifact@v4
        with:
          name: bandit-report
          path: ./app/python/bandit-report.json

      - name: Upload Safety Report
        if: always()  # Always upload, even if workflow fails
        uses: actions/upload-artifact@v4
        with:
          name: safety-report
          path: ./app/python/safety-report.json 

  build:
    needs: scan # Ensure deploy only happens after the scan job
    if: ${{ github.event.inputs.action == 'apply' && success() }}
    runs-on: ubuntu-latest
    steps:
    
    # Checkout code from the repository
    - name: Checkout code
      uses: actions/checkout@v2

    # Set up Docker Buildx (required for multi-platform builds)
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    # Set up Docker
    - name: Set up Docker
      uses: docker/setup-qemu-action@v2

    # Build the Docker image
    - name: Build Docker image
      run: |
        docker build -t michaelkedey/jomacsdevsecops:latest -f app/containerization/Dockerfile app/python/

    # Install Trivy
    - name: Install Trivy
      run: |
        curl -sfL https://github.com/aquasecurity/trivy/releases/download/v0.40.0/trivy_0.40.0_Linux-64bit.deb -o trivy.deb
        sudo dpkg -i trivy.deb

    # Scan the Docker image for vulnerabilities using Trivy
    - name: Scan Docker image for vulnerabilities
      id: trivy_scan
      run: |
        mkdir -p trivy-reports
        trivy image --no-progress --severity HIGH,CRITICAL --format json --output trivy-reports/scan-report.json michaelkedey/jomacsdevsecops:latest

    # Upload the Trivy scan report as an artifact (so you can download it later)
    - name: Upload Trivy scan report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: trivy-scan-report
        path: trivy-reports/scan-report.json
    
    # If no vulnerabilities with high severity are found, push to Docker Hub
    - name: Push Docker image to Docker Hub
      if: ${{ success() }}
      env:
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
      run: |
        echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin
        docker push michaelkedey/jomacsdevsecops:latest

  deploy-app:
    needs: [terraform-apply, scan] # Ensure deploy only happens after the scan job
    if: ${{ github.event.inputs.action == 'apply' && success() }}  # Only run if the scan job succeeds
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2    
      # 6. Set up SSH key and establish SSH Tunnel
      - name: Set up SSH tunnel and deploy code
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          BASTION: ${{ needs.terraform.outputs.bastion_ip }}
          HOST: ${{ needs.terraform.outputs.ec2_ip }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}

        run: |
          echo "waiting for instances to be ready"
          sleep 80

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem
          
          # Establish the SSH tunnel from GitHub Actions to the target EC2 instance
          # This command forwards the local port ${TUNNEL} to the target EC2 instance's SSH (port 22)
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${HOST}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f
      # 7. copy code and deploy 
      - name: Deploy app and start Gunicorn
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}
          HOST: ${{ needs.terraform.outputs.ec2_ip }}
        run: |
          rsync -avz -e "ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no" ./app/python/ ${USER}@localhost:/home/${USER}/my-app/
          
          # SSH into the EC2 instance and install dependencies and start Gunicorn
          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF'
            # Install dependencies
            cd /home/${USER}/my-app/
            sudo apt-get update -y -y && sudo apt-get upgrade -y
            sudo apt-get install python3-pip -y
            sudo apt-get install gunicorn -y
            sudo apt-get install python3-flask -y
            pip install -r requirements.txt
            # Start Gunicorn
            sudo nohup gunicorn -w 4 -b 0.0.0.0:80 app:app > gunicorn.log 2>&1 &
            echo "gunicorn log"
            sudo cat gunicorn.log
          EOF
          # 8. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always()  # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${{ inputs.ec2_ip }}"
          echo "SSH tunnel terminated"

  deploy-elk:
    needs: terraform-apply  # Ensure deploy only happens after the scan job
    if: ${{ github.event.inputs.action == 'apply' && success() }}  # Only run if the app deploy job succeeds
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2    
      # 6. Set up SSH key and establish SSH Tunnel
      - name: Set up SSH tunnel and deploy code
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          BASTION: ${{ needs.terraform.outputs.bastion_ip }}
          ELK: ${{ needs.terraform.outputs.elk_ip }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
        run: |
          echo "waiting for instances to be ready"
          sleep 80

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem
          
          # Establish the SSH tunnel from GitHub Actions to the target EC2 instance
          # This command forwards the local port ${TUNNEL} to the target EC2 instance's SSH (port 22)
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${ELK}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f
      # 7. deploy elk
      - name: Deploy and start elk stack
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
          PASSWORD: ${{ secrets.KIBANA_PASSWORD }}
          ELK: ${{ needs.terraform.outputs.elk_ip }}
        run: |
          # SSH into the EC2 instance and install elk and start it
          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF'
            # Update package index
            sudo apt-get update -y -y && sudo apt-get upgrade -y

            # Install Java (required by Elasticsearch)
            sudo apt-get install -y openjdk-11-jdk

            if ! systemctl list-units --type=service --all | grep -q elasticsearch.service; then
              echo "Installing Elasticsearch..."
              # Download and install the public signing key
              wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
              sudo apt-get install apt-transport-https
              echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
              sudo apt-get update -y && sudo apt-get install elasticsearch
              sudo /bin/systemctl daemon-reload
              sudo /bin/systemctl enable elasticsearch.service
              echo "waiting for elasticsearch to fully install before starting it"
              sleep 30 
              sudo systemctl start elasticsearch.service
              sleep 40
              echo "Getting enrollment token..."
              TOKEN=$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
              echo "Exporting the token to use later"
              export ENROLLMENT_TOKEN="$TOKEN"
            else
              echo "Elasticsearch already installed."
              sudo systemctl restart elasticsearch
              sleep 10
            fi

            # Install Kibana
            if ! systemctl list-units --type=service --all | grep -q kibana.service; then
              echo "Installing Kibana..."
              sudo apt-get update -y && sudo apt-get install kibana

              # Configure Kibana to listen on all interfaces
              sudo sed -i "s|^#\?server.host:.*|server.host: \"0.0.0.0\"|" /etc/kibana/kibana.yml

              # Add basePath configs and set elasticsearch address (if needed)
              echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml
              echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml
              sudo sed -i "s|^#\?elasticsearch.hosts:.*|elasticsearch.hosts: [\"http://localhost:9200\"]|" /etc/kibana/kibana.yml
              echo "passing token to kibana"
              sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "$ENROLLMENT_TOKEN"
              echo "starting kibana"
              sleep 10
              sudo systemctl start kibana
              sleep 10
            else
              echo "Kibana already installed."
              sudo systemctl restart kibana
              sleep 10
            fi

            # Install Logstash
            if ! systemctl list-units --type=service --all | grep -q logstash.service; then
              echo "Installing Logstash..."
              sudo apt-get update -y && sudo apt-get install logstash
              echo "starting logstash"
              sleep 10
              sudo systemctl start logstash.service
            else
              echo "Logstash already installed."
              sudo systemctl restart logstash
              sleep 10
            fi

            # checks
            sudo systemctl status elasticsearch
            sudo systemctl status logstash
            sudo systemctl status kibana
          EOF

      # 8. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always()  # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${{ inputs.ec2_ip }}"
          echo "SSH tunnel terminated"

  terraform-destroy:
    name: "Terraform Destroy"
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    defaults:
      run:
        working-directory: infra/aws/
    # Only run if "destroy" is selected manually
    if: github.event.inputs.action == 'destroy'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.1

      - name: Terraform Init
        run: terraform init

      - name: Terraform Destroy
        run: terraform destroy -auto-approve
  