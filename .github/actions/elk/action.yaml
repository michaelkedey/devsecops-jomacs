name: Deploy ELK Stack
description: Deploy and configure the ELK stack

inputs:
  log_file:
    description: 'Name of the log file.'
    required: true
     
  EC2_USER:
    description: 'EC2 username for SSH connection.'
    required: true
     
  ELK_TUNNEL_PORT:
    description: 'Port used for SSH tunneling to the ELK instance.'
    required: true
     
  LOGSTASH_PORT:
    description: 'Port for Logstash input.'
    required: true
     
  ELASTICSEARCH_PORT:
    description: 'Port for Elasticsearch service.'
    required: true
     
  EC2_SSH_KEY:
    description: 'Private key for EC2 SSH access.'
    required: true
     
  AWS_ACCESS_KEY_ID:
    description: 'AWS Access Key ID for uploading logs.'
    required: true
     
  AWS_SECRET_ACCESS_KEY:
    description: 'AWS Secret Access Key for uploading logs.'
    required: true
     
  AWS_REGION:
    description: 'AWS region for S3 uploads.'
    required: true
     
  DEVSECOPS_GPG_PASSPHRASE:
    description: 'GPG passphrase used for encrypting files.'
    required: true


runs:
  using: "composite"
  steps:
    # 1. Checkout Code from GitHub
    - name: Checkout Code
      uses: actions/checkout@v4

    # 3. deploy elk
    - name: Deploy and start elk stack
      env:
        USER: ${{  inputs.EC2_USER }}
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
        LOGSTASH_PORT: ${{  inputs.LOGSTASH_PORT }}
        ELASTICSEARCH_PORT: ${{  inputs.ELASTICSEARCH_PORT }}
        PRIVATE_KEY: ${{ inputs.EC2_SSH_KEY }}
        GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
        LOGS_SEPARATOR: "=================================================================================================================================================================================="
      run: |
        set -e

        echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

        # SSH into the EC2 instance and install elk and start it
        ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << EOF | tee ${{ inputs.log_file }}         
          
          set -euo pipefail  # Exit on error, undefined variables, or pipe failures

          echo "${LOGS_SEPARATOR}"
          # Wait for apt lock to be released
          echo "Waiting for apt lock to start installing..."
          while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
              sleep 2
          done
          echo "apt lock ready"
          echo "updating system"
          sudo apt-get update -y && sudo apt-get upgrade -y

          echo "Installing Java."
          # Install Java (required by Elasticsearch)
          echo "${LOGS_SEPARATOR}"
          sudo apt-get install -y openjdk-11-jdk jq

          echo "Installing Elasticsearch."
          echo "${LOGS_SEPARATOR}"
          if ! dpkg -s elasticsearch &>/dev/null; then
            wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --batch --yes --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
            sudo apt-get install apt-transport-https
            echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
            sudo apt-get update && sudo apt-get install elasticsearch
            sleep 15
            sudo /bin/systemctl daemon-reload
            sudo /bin/systemctl enable elasticsearch.service
            sleep 30
            echo "${LOGS_SEPARATOR}"
            echo "starting elasticsearch"
            sudo systemctl start elasticsearch.service
            sleep 30
            echo "${LOGS_SEPARATOR}"
            echo "regenerating elasticsearch password"
            ELASTIC_PASSWORD=\$(sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -b | sed -n 's/^New value: //p')
            sleep 10
            echo "${LOGS_SEPARATOR}"
            echo "gpg encryption of password"
            echo "\${ELASTIC_PASSWORD}" > elastic_password.txt
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 elastic_password.txt
            rm elastic_password.txt

            sudo cp /etc/kibana/certs/http_ca.crt /usr/local/share/ca-certificates/http_ca.crt
            sudo update-ca-certificates

          else
            echo "Elasticsearch already installed."  
          fi

          sudo cp /etc/kibana/certs/http_ca.crt /usr/local/share/ca-certificates/http_ca.crt
          sudo update-ca-certificates

          echo "${LOGS_SEPARATOR}"
          echo "setting elsaticsearch configs"
          sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          echo "${LOGS_SEPARATOR}"
          echo "restarting elasticsearch"
          sudo systemctl restart elasticsearch


          echo "Installing Kibana."
          echo "${LOGS_SEPARATOR}"
          if ! dpkg -s kibana &>/dev/null; then
            sudo apt-get update && sudo apt-get install kibana
            sleep 10
            sudo /bin/systemctl daemon-reload
            sudo /bin/systemctl enable kibana.service
            sleep 10
            sudo systemctl start kibana.service

            echo "${LOGS_SEPARATOR}"
            echo "checking cluster health to set kibana token"
            echo "decrypting elastic password"
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt elastic_password.txt.gpg > elastic_password.txt
            ELASTIC_PASSWORD=\$(< elastic_password.txt)
            echo "checkinh health"
            MAX_RETRIES=12
            RETRY_COUNT=0

            until sudo curl -s -u elastic:\$ELASTIC_PASSWORD https://localhost:9200/_cluster/health \
            | grep -E -q '"status":"green"|"status":"yellow"'; do
              if [ \$RETRY_COUNT -ge \$MAX_RETRIES ]; then
                echo "Elasticsearch cluster failed to become healthy after \$((MAX_RETRIES * 5)) seconds."
                echo "Attempting to restart Elasticsearch..."
                sudo systemctl restart elasticsearch

                sleep 30
                RETRY_COUNT=0  # Reset count to re-check after restart
                MAX_RETRIES=6  # Give fewer retries after restart
              else
                echo "Waiting for Elasticsearch to become healthy... (\${RETRY_COUNT}/\${MAX_RETRIES})"
                sleep 5
                RETRY_COUNT=\$((RETRY_COUNT + 1))
              fi
            done
            rm elastic_password.txt
            
            echo "${LOGS_SEPARATOR}"
            echo "setting enrolment token."
            TOKEN=\$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
            sleep 20
            echo "applying token to kibana setup."
            sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "\$TOKEN"

            echo "${LOGS_SEPARATOR}"
            echo "setting kibana reporting key."
            # Generate a random 32-byte string, base64 encode it
            KIBANA_KEY=\$(sudo openssl rand -base64 32)
            echo "settign kibana reporting key"
            sudo sed -i '/^#\?xpack\.reporting\.encryptionKey:/d' /etc/kibana/kibana.yml && echo "xpack.reporting.encryptionKey: \"\${KIBANA_KEY}\"" | sudo tee -a /etc/kibana/kibana.yml > /dev/null
            sudo sed -i '/^#\?xpack\.encryptedSavedObjects\.encryptionKey:/d' /etc/kibana/kibana.yml && echo "xpack.encryptedSavedObjects.encryptionKey: \"\${KIBANA_KEY}\"" | sudo tee -a /etc/kibana/kibana.yml > /dev/null

            echo "${LOGS_SEPARATOR}"
            echo "gpg encryption of token and key"
            echo "\${TOKEN}" > kibana_setup_token.txt
            echo "\${KIBANA_KEY}" > kibana_reporting_key.txt
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 kibana_setup_token.txt
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 kibana_reporting_key.txt
            rm kibana_setup_token.txt
            rm kibana_reporting_key.txt
          else
            echo "Kibana already installed."
          fi

          echo "${LOGS_SEPARATOR}"
          echo "setting kibana configs"
          sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null          
          
          echo "${LOGS_SEPARATOR}"
          echo "configuring kibana certs" 
          sudo mkdir -p /etc/kibana/certs
          sudo cp /etc/elasticsearch/certs/http_ca.crt /etc/kibana/certs/
          sudo chown root:kibana /etc/kibana/certs/http_ca.crt
          sudo chmod 640 /etc/kibana/certs/http_ca.crt
          sudo sed -i '/^#\?elasticsearch\.ssl\.certificateAuthorities:/d' /etc/kibana/kibana.yml && echo 'elasticsearch.ssl.certificateAuthorities: ["/etc/kibana/certs/http_ca.crt"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

          echo "${LOGS_SEPARATOR}"
          echo "restarting kibana"
          sudo systemctl restart kibana.service


          echo "${LOGS_SEPARATOR}"
          echo "Installing Logstash."
          if ! dpkg -s logstash &>/dev/null; then
            echo "Installing Logstash..."
            sudo apt-get update -y && sudo apt-get install logstash
            sudo systemctl enable logstash.service  
            sudo systemctl start logstash.service

            echo "${LOGS_SEPARATOR}"
            echo "checking cluster health to set logstash elasticsearch api"
            echo "decrypting elastic password"
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt elastic_password.txt.gpg > elastic_password.txt
            ELASTIC_PASSWORD=\$(< elastic_password.txt)
            echo "checkinh health"
            MAX_RETRIES=12
            RETRY_COUNT=0

            until sudo curl -s -u elastic:\$ELASTIC_PASSWORD https://localhost:9200/_cluster/health \
            | grep -E -q '"status":"green"|"status":"yellow"'; do
              if [ \$RETRY_COUNT -ge \$MAX_RETRIES ]; then
                echo "Elasticsearch cluster failed to become healthy after \$((MAX_RETRIES * 5)) seconds."
                echo "Attempting to restart Elasticsearch..."
                sudo systemctl restart elasticsearch

                sleep 30
                RETRY_COUNT=0  # Reset count to re-check after restart
                MAX_RETRIES=6  # Give fewer retries after restart
              else
                echo "Waiting for Elasticsearch to become healthy... (\${RETRY_COUNT}/\${MAX_RETRIES})"
                sleep 5
                RETRY_COUNT=\$((RETRY_COUNT + 1))
              fi
            done

            echo "${LOGS_SEPARATOR}"
            echo "Generate api key for logstash kibana auth"
            LOGSTASH_API_KEY_JSON=$(sudo curl -X POST -u elastic:\$ELASTIC_PASSWORD \
            -H "Content-Type: application/json" \
            "https://localhost:9200/_security/api_key?pretty" \
            -d '{
                  "name": "logstash-api-key",
                  "role_descriptors": {
                    "logstash_writer": {
                      "cluster": ["monitor", "manage_index_templates"],
                      "indices": [
                        {
                          "names": ["flask-logs-*"],
                          "privileges": ["create_index", "write", "read"]
                        }
                      ]
                    }
                  }
                }')

            echo "${LOGS_SEPARATOR}"
            echo "gpg encryption of api keys"
            echo "\$LOGSTASH_API_KEY_JSON" > logstash_api_key.json
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 logstash_api_key.json
            rm logstash_api_key.json
            rm elastic_password.txt

            echo "restarting logstash"
            sudo systemctl restart logstash

            # echo "${LOGS_SEPARATOR}"
            # echo "Creating Logstash keystore if not exists"
            # sudo mkdir -p /etc/logstash
            # sudo chown -R logstash:logstash /etc/logstash
            # sudo chmod 755 /etc/logstash
            
            # #LOGSTASH_KEYSTORE_PASS=\$(openssl rand -base64 32)
            # LOGSTASH_KEYSTORE_PASS=$(openssl rand -base64 16 | tr -dc '[:alnum:]')  # Ensure ASCII characters only
            # export LOGSTASH_KEYSTORE_PASS
            # echo y | sudo --preserve-env=LOGSTASH_KEYSTORE_PASS -u logstash \
            # /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash create

            # echo "${LOGS_SEPARATOR}"
            # echo "Storing key id and secret in Logstash keystore"
            # echo "$API_KEY_ID" | sudo /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash add ES_API_KEY_ID --stdin
            # echo "$API_KEY_SECRET" | sudo /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash add ES_API_KEY_SECRET --stdin
            
            #rm elastic_password.txt
          else
            echo "Logstash already installed."
            echo "restarting logstash"
            sudo systemctl restart logstash
          fi

  
          echo "${LOGS_SEPARATOR}"
          echo "logstash config file"
          echo "decrypting api key to extract id and seceret"
          gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt logstash_api_key.json.gpg > logstash_api_key.json.gpg
          LOGSTASH_API_KEY_JSON=\$(< logstash_api_key.json)

          echo "${LOGS_SEPARATOR}"
          echo "Extracting API key credentials"
          API_KEY_ID=\$(echo "$LOGSTASH_API_KEY_JSON" | jq -r '.id')
          API_KEY_SECRET=\$(echo "$LOGSTASH_API_KEY_JSON" | jq -r '.api_key')

          echo "${LOGS_SEPARATOR}"
          echo "gpg encryption of api keys"
          echo "\$API_KEY_ID" > logstash_api_key_id.json
          echo "\$API_KEY_SECRET" > logstash_api_key_secret.json
          gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 logstash_api_key_secret.json
          gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 logstash_api_key_id.json
          rm logstash_api_key_id.json 
          rm logstash_api_key_secret.json
          rm logstash_api_key.json

          echo "${LOGS_SEPARATOR}"
            echo "logstash config file"
            sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH_CONFIG
              input {
                beats {
                  port => ${LOGSTASH_PORT}
                }
              }

              filter {
                grok {
                  match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
                }
                date {
                  match => ["timestamp", "ISO8601"]
                }
              }

              output {
                elasticsearch {
                  hosts => ["https://localhost:${ELASTICSEARCH_PORT}"]
                  ssl => true
                  ssl_certificate_verification => true
                  cacert => "/etc/elasticsearch/certs/http_ca.crt"
                  index => "flask-logs-%{+YYYY.MM.dd}"
                  api_key => "\$API_KEY_ID:\$API_KEY_SECRET"
                  retry_initial_interval => 3
                  retry_max_interval => 60
                  retry_on_conflict => 3
                }
              }
        LOGSTASH_CONFIG
          echo "restarting logstash"
          sudo systemctl restart logstash

          #checks
          sleep 20
          echo "${LOGS_SEPARATOR}"
          echo "checking cluster health to check elasticsearch status"
          echo "decrypting elastic password"
          gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt elastic_password.txt.gpg > elastic_password.txt
          ELASTIC_PASSWORD=\$(< elastic_password.txt)
          echo "checkinh health"
          MAX_RETRIES=12
          RETRY_COUNT=0

          until sudo curl -s -u elastic:\$ELASTIC_PASSWORD https://localhost:9200/_cluster/health \
          | grep -E -q '"status":"green"|"status":"yellow"'; do
            if [ \$RETRY_COUNT -ge \$MAX_RETRIES ]; then
              echo "Elasticsearch cluster failed to become healthy after \$((MAX_RETRIES * 5)) seconds."
              echo "Attempting to restart Elasticsearch..."
              sudo systemctl restart elasticsearch

              sleep 30
              RETRY_COUNT=0  # Reset count to re-check after restart
              MAX_RETRIES=6  # Give fewer retries after restart
            else
              echo "Waiting for Elasticsearch to become healthy... (\${RETRY_COUNT}/\${MAX_RETRIES})"
              sleep 5
              RETRY_COUNT=\$((RETRY_COUNT + 1))
            fi
          done
          rm elastic_password.txt
          echo "cluster healthy"
          sudo systemctl restart logstash
          sudo systemctl restart kibana

          echo "${LOGS_SEPARATOR}"
          echo "service status checks"
          sudo systemctl status elasticsearch
          sudo systemctl status logstash
          sudo systemctl status kibana
        EOF
      shell: bash

    - name: Copy encrypted password from EC2 and upload
      env:
        USER: ${{  inputs.EC2_USER }}
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
        PRIVATE_KEY: ${{ inputs.EC2_SSH_KEY }}
        AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{  inputs.AWS_REGION }}
      run: |
        echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

        echo "${LOGS_SEPARATOR}"
        echo "scp the gpg encrypted password"
        scp -i private_key.pem -P ${{ inputs.ELK_TUNNEL_PORT }} -o StrictHostKeyChecking=no ${USER}@localhost:/home/${USER}/elastic_password.txt.gpg .

        echo "upload password to s3"
        aws s3 cp elastic_password.txt.gpg s3://sedem-terra333-bucket/devsecops-jomacs/elastic_password.txt.gpg
      shell: bash

    - name: Encrypt and upload logs to s3
      env:
        AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{  inputs.AWS_REGION }}
        GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
        LOGS_SEPARATOR: "=================================================================================================================================================================================="
      run: |
        
        echo "${LOGS_SEPARATOR}"
        echo "Encrypting and uploading the log file using the GPG passphrase"
        gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 ${{ inputs.log_file }} 
        aws s3 cp ${{ inputs.log_file }}.gpg  s3://sedem-terra333-bucket/devsecops-jomacs/logs/${{ inputs.log_file }}.gpg

        echo "${LOGS_SEPARATOR}"
        echo "removing generated files"

        rm ${{ inputs.log_file }}.gpg
        rm ${{ inputs.log_file }}
        rm elastic_password.txt.gpg
      shell: bash

    # 4. Clean-up tunnel
    - name: Cleanup SSH Tunnel
      env:
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
      if: always() # Runs even if previous steps fail
      run: |
        # Kill tunnel process using port ${TUNNEL}
        pkill -f "ssh.*${TUNNEL}:.*${ELK}"
        rm -f private_key.pem
        echo "SSH tunnel terminated"
      shell: bash 
























# name: Deploy ELK Stack

# on:
#   workflow_call:  # Only callable by other workflows
#     inputs:
#       log_file:
#         required: true
#          

# jobs:
#   elk-deploy:
#       runs-on: ubuntu-latest
#       steps:
#         # 1. Checkout Code from GitHub
#         - name: Checkout Code
#           uses: actions/checkout@v4

#         # 3. deploy elk
#         - name: Deploy and start elk stack
#           env:
#             USER: ${{  inputs.EC2_USER }}
#             TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
#             LOGSTASH_PORT: ${{  inputs.LOGSTASH_PORT }}
#             ELASTICSEARCH_PORT: ${{  inputs.ELASTICSEARCH_PORT }}
#             PRIVATE_KEY: ${{  inputs.EC2_SSH_KEY }}
#              LOGS_SEPARATOR: "=================================================================================================================================================================================="
            
#           run: |
#             set -e
#             export LOGSTASH_PORT=${{  inputs.LOGSTASH_PORT }}
#             export ELASTICSEARCH_PORT=${{  inputs.ELASTICSEARCH_PORT }}
#             export LOGS_SEPARATOR=${LOGS_SEPARATOR}

#             echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

#             # SSH into the EC2 instance and install elk and start it
#             ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF' | tee ${{ inputs.log_file }}         
#               echo "${LOGS_SEPARATOR}"

#               # Update package index
#               echo "updating system"
#               sudo apt-get update -y && sudo apt-get upgrade -y

#               echo "Installing Java."
#               # Install Java (required by Elasticsearch)
#               echo "${LOGS_SEPARATOR}"
#               sudo apt-get install -y openjdk-11-jdk

#               echo "Installing Elasticsearch."
#               echo "${LOGS_SEPARATOR}"
#               if ! dpkg -s elasticsearch &>/dev/null; then
#                 wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
#                 sudo apt-get install apt-transport-https
#                 echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
#                 sudo apt-get update && sudo apt-get install elasticsearch
#                 sleep 15
#                 sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo /bin/systemctl daemon-reload
#                 sudo /bin/systemctl enable elasticsearch.service
#                 sleep 30
#                 sudo systemctl start elasticsearch.service
#                 sleep 30
                  
#                 echo "Generating the Elasticsearch password for the 'elastic' user."
#                 echo "${LOGS_SEPARATOR}"
#                 ELASTIC_PASSWORD=$(sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -b | awk '/New value:/ {print $NF}')
#                 sleep 15
#                 echo "$ELASTIC_PASSWORD" > elastic_password.txt
                
#                 echo "FILE_TRANSFER_START"
#                 base64 elastic_password.txt
#                 echo "FILE_TRANSFER_END"

#                 rm elastic_password.txt
                  
#               else
#                 echo "Elasticsearch already installed."
#                 sudo systemctl restart elasticsearch
#                 sleep 10
#               fi

#               echo "Installing Kibana."
#               echo "${LOGS_SEPARATOR}"
#               if ! dpkg -s kibana &>/dev/null; then
#                 sudo apt-get update && sudo apt-get install kibana
#                 sleep 10
#                 sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set server.basePath
#                 sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set server.rewriteBasePath
#                 sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set elasticsearch.hosts
#                 sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && \
#                 echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
                
#                 echo "${LOGS_SEPARATOR}"
#                 echo "seting enrolment token."
#                 TOKEN=$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
#                 sleep 20

#                 echo "${LOGS_SEPARATOR}"
#                 echo "applying token to kibana setup."
#                 sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "$TOKEN"

#                 sudo /bin/systemctl daemon-reload
#                 sudo /bin/systemctl enable kibana.service
#                 sleep 10
#                 sudo systemctl start kibana.service
#               else
#                 echo "Kibana already installed. Restarting..."
#                 sudo systemctl restart kibana
#               fi

#               echo "${LOGS_SEPARATOR}"
#               echo "Installing Logstash."
#               if ! dpkg -s logstash &>/dev/null; then
#                 echo "Installing Logstash..."
#                 sudo apt-get update -y && sudo apt-get install logstash
#                 sudo systemctl enable logstash.service  
#                 sudo systemctl start logstash.service

#                 echo "${LOGS_SEPARATOR}"
#                 echo "Configuring logstash"
#                 sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH_CONFIG
#                   input {
#                     beats {
#                       port => ${LOGSTASH_PORT}
#                     }
#                   }

#                   filter {
#                     grok {
#                       match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
#                     }
#                     date {
#                       match => ["timestamp", "ISO8601"]
#                     }
#                   }

#                   output {
#                     elasticsearch {
#                       hosts => ["https://localhost:${ELASTICSEARCH_PORT}"]
#                       index => "flask-logs-%{+YYYY.MM.dd}"
#                       user => "elastic"
#                       password => "${ELASTIC_PASSWORD}"
#                       ssl => true
#                       cacert => "/etc/elasticsearch/certs/http_ca.crt"
#                     }
#                   }
#             LOGSTASH_CONFIG
#               echo "restarting logstash"
#               sudo systemctl restart logstash

#               else
#                 echo "Logstash already installed."
#                 sudo systemctl restart logstash
#                 sleep 10
#               fi

#               checks
#               sudo systemctl status elasticsearch
#               sudo systemctl status logstash
#               sudo systemctl status kibana
#             EOF

#         - name: Encrypt and upload logs to s3
#           env:
#             AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
#             AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
#             AWS_REGION: ${{  inputs.AWS_REGION }}
#             GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
#              LOGS_SEPARATOR: "=================================================================================================================================================================================="
#           run: |
#             echo "${LOGS_SEPARATOR}"
#             echo "Extracting and encoding elasticsearch password from heredoc."
#             awk '/FILE_TRANSFER_START/{flag=1;next} /FILE_TRANSFER_END/{flag=0} flag' ${{ inputs.log_file }}  | base64 -d > elastic_password.txt
#             gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 elastic_password.txt
#             aws s3 cp elastic_password.txt.gpg s3://sedem-terra333-bucket/devsecops-jomacs/elastic_password.txt.gpg

#             echo "${LOGS_SEPARATOR}"
#             echo "Encrypting and uploading the log file using the GPG passphrase stored in GitHub  inputs.==="
#             gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 ${{ inputs.log_file }} 
#             aws s3 cp ${{ inputs.log_file }}.gpg  s3://sedem-terra333-bucket/devsecops-jomacs/logs/${{ inputs.log_file }}.gpg

#             echo "${LOGS_SEPARATOR}"
#             echo "removing generated files"
#             rm ${{ inputs.log_file }} 
#             rm ${{ inputs.log_file }}.gpg
#             rm elastic_password.txt
#             rm elastic_password.txt.gpg
            
#         # 4. Clean-up tunnel
#         - name: Cleanup SSH Tunnel
#           if: always() # Runs even if previous steps fail
#           run: |
#             # Kill tunnel process using port ${TUNNEL}
#             pkill -f "ssh.*${TUNNEL}:.*${ELK}"
#             rm -f private_key.pem
#             echo "SSH tunnel terminated"