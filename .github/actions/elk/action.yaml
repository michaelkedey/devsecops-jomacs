name: Deploy ELK Stack
description: Deploy and configure the ELK stack

inputs:
  log_file:
    description: 'Name of the log file.'
    required: true
     
  EC2_USER:
    description: 'EC2 username for SSH connection.'
    required: true
     
  ELK_TUNNEL_PORT:
    description: 'Port used for SSH tunneling to the ELK instance.'
    required: true
     
  LOGSTASH_PORT:
    description: 'Port for Logstash input.'
    required: true
     
  ELASTICSEARCH_PORT:
    description: 'Port for Elasticsearch service.'
    required: true
     
  EC2_SSH_KEY:
    description: 'Private key for EC2 SSH access.'
    required: true
     
  AWS_ACCESS_KEY_ID:
    description: 'AWS Access Key ID for uploading logs.'
    required: true
     
  AWS_SECRET_ACCESS_KEY:
    description: 'AWS Secret Access Key for uploading logs.'
    required: true
     
  AWS_REGION:
    description: 'AWS region for S3 uploads.'
    required: true
     
  DEVSECOPS_GPG_PASSPHRASE:
    description: 'GPG passphrase used for encrypting files.'
    required: true

  ALB_DNS:
    description: 'loadbalancer url'
    required: true


runs:
  using: "composite"
  steps:
    # 1. Checkout Code from GitHub
    - name: Checkout Code
      uses: actions/checkout@v4

    # 3. deploy elk
    - name: Deploy and start elk stack
      env:
        USER: ${{  inputs.EC2_USER }}
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
        LOGSTASH_PORT: ${{  inputs.LOGSTASH_PORT }}
        ELASTICSEARCH_PORT: ${{  inputs.ELASTICSEARCH_PORT }}
        PRIVATE_KEY: ${{ inputs.EC2_SSH_KEY }}
        GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
        ALB_DNS: ${{ inputs.ALB_DNS }}
        LOGS_SEPARATOR: "=================================================================================================================================================================================="
      run: |
        set -e

        echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

        # SSH into the EC2 instance and install elk and start it
        ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << EOF | tee ${{ inputs.log_file }}         
          
          set -euo pipefail  # Exit on error, undefined variables, or pipe failures

          echo "${LOGS_SEPARATOR}"
          # Wait for apt lock to be released
          echo "Waiting for apt lock to start installing..."
          while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
              sleep 2
          done
          echo "apt lock ready"
          echo "updating system"
          sudo apt-get update -y && sudo apt-get upgrade -y

          echo "Installing Java."
          # Install Java (required by Elasticsearch)
          echo "${LOGS_SEPARATOR}"
          sudo apt-get install -y openjdk-11-jdk jq

          echo "Installing Elasticsearch."
          echo "${LOGS_SEPARATOR}"
          if ! dpkg -s elasticsearch &>/dev/null; then
            wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --batch --yes --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
            sudo apt-get install apt-transport-https
            echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
            sudo apt-get update && sudo apt-get install elasticsearch
            sleep 15
            sudo /bin/systemctl daemon-reload
            sudo /bin/systemctl enable elasticsearch.service
            sleep 30
            echo "${LOGS_SEPARATOR}"
            echo "starting elasticsearch"
            sudo systemctl start elasticsearch.service
            sleep 30
            echo "${LOGS_SEPARATOR}"
            echo "regenerating elasticsearch password"
            ELASTIC_PASSWORD=\$(sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -b | sed -n 's/^New value: //p')
            sleep 10
            echo "${LOGS_SEPARATOR}"
            echo "gpg encryption of password"
            printf "%s\n" "\${ELASTIC_PASSWORD}" | gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 -o elastic_password.txt.gpg
            echo "${LOGS_SEPARATOR}"
            echo "starting cluster"
            sudo systemctl start elasticsearch
          else
            echo "Elasticsearch already installed."  
          fi

          echo "${LOGS_SEPARATOR}"
          echo "setting elsaticsearch configs"
          sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
          sudo cp /etc/elasticsearch/certs/http_ca.crt /usr/local/share/ca-certificates/http_ca.crt
          sudo update-ca-certificates
          echo "${LOGS_SEPARATOR}"
          echo "restarting elasticsearch"
          sudo systemctl restart elasticsearch.service
          sleep 30


          echo "creating function to check cluster health"
          check_cluster_health() {
            local ELASTIC_PASSWORD=\$(gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt --quiet elastic_password.txt.gpg)
            local MAX_RETRIES=36
            local MAX_TOTAL_RETRIES=4
            local RETRY_COUNT=0
            local TOTAL_RETRIES=0

            echo "Checking Elasticsearch health..."
            until sudo curl -s -u elastic:"\$ELASTIC_PASSWORD" https://localhost:9200/_cluster/health \
              | grep -Eq '"status":"green"|"status":"yellow"'; do

              if [ "\$RETRY_COUNT" -ge "\$MAX_RETRIES" ]; then
                if [ "\$TOTAL_RETRIES" -ge "\$MAX_TOTAL_RETRIES" ]; then
                  echo " Maximum retry attempts reached. Exiting..."
                  return 1
                fi
                echo " Cluster unhealthy after \$((MAX_RETRIES * 5)) seconds. Restarting Elasticsearch..."
                sudo systemctl restart elasticsearch
                sleep 60
                RETRY_COUNT=0
                MAX_RETRIES=18
                TOTAL_RETRIES=\$((TOTAL_RETRIES + 1))
              else
                echo "Waiting for cluster to become healthy... (\$RETRY_COUNT/\$MAX_RETRIES)"
                sleep 5
                RETRY_COUNT=\$((RETRY_COUNT + 1))
              fi
            done
            echo " Elasticsearch cluster is healthy."
          }


          echo "Installing Kibana."
          echo "${LOGS_SEPARATOR}"
          if ! dpkg -s kibana &>/dev/null; then
            sudo apt-get update && sudo apt-get install kibana
            sleep 10
            sudo /bin/systemctl daemon-reload
            sudo /bin/systemctl enable kibana.service
            sleep 10
            sudo systemctl start kibana.service

            echo "${LOGS_SEPARATOR}"
            echo "checking cluster health to set kibana token"
            check_cluster_health

            echo "${LOGS_SEPARATOR}"
            echo "setting enrolment token."
            TOKEN=\$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
            sleep 20
            echo "applying token to kibana setup."
            sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "\$TOKEN"
            echo "${LOGS_SEPARATOR}"
            echo "setting kibana reporting key."
            # Generate a random 32-byte string, base64 encode it
            KIBANA_KEY=\$(sudo openssl rand -base64 32)
            echo "settign kibana reporting key"
            sudo sed -i '/^#\?xpack\.reporting\.encryptionKey:/d' /etc/kibana/kibana.yml && echo "xpack.reporting.encryptionKey: \"\${KIBANA_KEY}\"" | sudo tee -a /etc/kibana/kibana.yml > /dev/null
            sudo sed -i '/^#\?xpack\.encryptedSavedObjects\.encryptionKey:/d' /etc/kibana/kibana.yml && echo "xpack.encryptedSavedObjects.encryptionKey: \"\${KIBANA_KEY}\"" | sudo tee -a /etc/kibana/kibana.yml > /dev/null
            echo "${LOGS_SEPARATOR}"
            echo "gpg encryption of token and key"
            echo "\${TOKEN}" > kibana_setup_token.txt
            echo "\${KIBANA_KEY}" > kibana_reporting_key.txt
            printf "%s\n" "\${TOKEN}" | gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 -o kibana_setup_token.gpg
            printf "%s\n" "\${KIBANA_KEY}" | gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 -o kibana_reporting_key.gpg
          else
            echo "Kibana already installed."
          fi

          echo "${LOGS_SEPARATOR}"
          echo "setting kibana configs"
          sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^server\.publicBaseUrl:/d' /etc/kibana/kibana.yml && echo "server.publicBaseUrl: \"http://${ALB_DNS}/elk\"" | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
          sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null          
          echo "${LOGS_SEPARATOR}"
          echo "configuring kibana certs" 
          sudo mkdir -p /etc/kibana/certs
          sudo cp /etc/elasticsearch/certs/http_ca.crt /etc/kibana/certs/
          sudo chown root:kibana /etc/kibana/certs/http_ca.crt
          sudo chmod 640 /etc/kibana/certs/http_ca.crt
          sudo sed -i '/^#\?elasticsearch\.ssl\.certificateAuthorities:/d' /etc/kibana/kibana.yml && echo 'elasticsearch.ssl.certificateAuthorities: ["/etc/kibana/certs/http_ca.crt"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null  
          echo "${LOGS_SEPARATOR}"
          echo "restarting kibana"
          sudo systemctl restart kibana.service
          
          # CSP Rules Configuration
          # sudo sed -i '/^csp\.rules:/d' /etc/kibana/kibana.yml
          # sudo sed -i '/^\s\+- "/d' /etc/kibana/kibana.yml

          # {
          #   echo "csp.rules:"
          #   echo "  - \"script-src 'unsafe-inline' 'self' http://${ALB_DNS}\""
          #   echo "  - \"style-src 'unsafe-inline' 'self'\""
          #   echo "  - \"font-src 'self' data:\""
          #   echo "  - \"connect-src 'self' http://${ALB_DNS}\""
          #   echo "  - \"img-src 'self' data:\""
          # } | sudo tee -a /etc/kibana/kibana.yml > /dev/null


          echo "${LOGS_SEPARATOR}"
          echo "Installing Logstash."
          if ! dpkg -s logstash &>/dev/null; then
            echo "Installing Logstash..."
            sudo apt-get update -y && sudo apt-get install logstash
            sudo systemctl enable logstash.service  
            sudo systemctl start logstash.service
            
            echo "${LOGS_SEPARATOR}"
            echo "checking cluster health to set logstash api key"
            check_cluster_health
            
            echo "${LOGS_SEPARATOR}"
            echo "Generate api key for logstash kibana auth"
            export ELASTIC_PASSWORD=\$(gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --decrypt --quiet elastic_password.txt.gpg)
            LOGSTASH_API_KEY=\$(curl -s -X POST -u "elastic:\${ELASTIC_PASSWORD}" \
              -H "Content-Type: application/json" \
              "https://localhost:9200/_security/api_key?pretty" \
              -d '{
                "name": "logstash-api-key",
                "role_descriptors": {
                  "logstash_writer": {
                    "cluster": ["monitor", "manage_index_templates"],
                    "index": [{
                      "names": ["flask-logs-*"],
                      "privileges": ["create_index", "write", "read"]
                    }]
                  }
                }
              }' | jq -r '"\(.id):\(.api_key)"')


            echo "${LOGS_SEPARATOR}"
            echo "GPg encryption of API keys"
            # Write raw JSON output with proper escaping
            printf "%s\n" "\${LOGSTASH_API_KEY}" > logstash_api_key
            gpg --batch --yes --passphrase "$GPG_PASSPHRASE" --symmetric --cipher-algo AES256 logstash_api_key

            echo "${LOGS_SEPARATOR}"
            echo "restarting logstash"
            sudo systemctl restart logstash

            # echo "${LOGS_SEPARATOR}"
            # echo "Creating Logstash keystore if not exists"
            # sudo mkdir -p /etc/logstash
            # sudo chown -R logstash:logstash /etc/logstash
            # sudo chmod 755 /etc/logstash
            
            # #LOGSTASH_KEYSTORE_PASS=\$(openssl rand -base64 32)
            # LOGSTASH_KEYSTORE_PASS=$(openssl rand -base64 16 | tr -dc '[:alnum:]')  # Ensure ASCII characters only
            # export LOGSTASH_KEYSTORE_PASS
            # echo y | sudo --preserve-env=LOGSTASH_KEYSTORE_PASS -u logstash \
            # /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash create

          else
            echo "Logstash already installed."
          fi

          echo "${LOGS_SEPARATOR}"
          echo "logstash config file"
          sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH
            input {
              beats {
                port => ${LOGSTASH_PORT}
              }
            }

            filter {
              grok {
                match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
              }
              date {
                match => ["timestamp", "ISO8601"]
              }
            }

            output {
              elasticsearch {
                hosts => ["https://localhost:${ELASTICSEARCH_PORT}"]
                ssl => true
                ssl_certificate_verification => true
                cacert => "/etc/elasticsearch/certs/http_ca.crt"
                index => "flask-logs-%{+YYYY.MM.dd}"
                api_key => "\${LOGSTASH_API_KEY}"
                retry_initial_interval => 3
                retry_max_interval => 60
                retry_on_conflict => 3
              }
            }
        LOGSTASH
          echo "restarting logstash"
          sudo systemctl restart logstash


          #checks
          sleep 10
          echo "${LOGS_SEPARATOR}"
          echo "checking cluster health to check status"
          check_cluster_health

          echo "${LOGS_SEPARATOR}"
          echo "service status checks"
          sudo systemctl status elasticsearch
          sudo systemctl status logstash
          sudo systemctl status kibana
        EOF
      shell: bash

    - name: Copy encrypted password from EC2 and upload
      env:
        USER: ${{  inputs.EC2_USER }}
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
        PRIVATE_KEY: ${{ inputs.EC2_SSH_KEY }}
        AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{  inputs.AWS_REGION }}
      run: |
        echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

        echo "${LOGS_SEPARATOR}"
        echo "scp the gpg encrypted password"
        scp -i private_key.pem -P ${{ inputs.ELK_TUNNEL_PORT }} -o StrictHostKeyChecking=no ${USER}@localhost:/home/${USER}/elastic_password.txt.gpg .

        echo "upload password to s3"
        aws s3 cp elastic_password.txt.gpg s3://sedem-terra333-bucket/devsecops-jomacs/elastic_password.txt.gpg
      shell: bash

    - name: Encrypt and upload logs to s3
      env:
        AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{  inputs.AWS_REGION }}
        GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
        LOGS_SEPARATOR: "=================================================================================================================================================================================="
      run: |
        
        echo "${LOGS_SEPARATOR}"
        echo "Encrypting and uploading the log file using the GPG passphrase"
        gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 ${{ inputs.log_file }} 
        aws s3 cp ${{ inputs.log_file }}.gpg  s3://sedem-terra333-bucket/devsecops-jomacs/logs/${{ inputs.log_file }}.gpg

        echo "${LOGS_SEPARATOR}"
        echo "removing generated files"

        rm ${{ inputs.log_file }}.gpg
        rm ${{ inputs.log_file }}
        rm elastic_password.txt.gpg
      shell: bash

    # 4. Clean-up tunnel
    - name: Cleanup SSH Tunnel
      env:
        TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
      if: always() # Runs even if previous steps fail
      run: |
        # Kill tunnel process using port ${TUNNEL}
        pkill -f "ssh.*${TUNNEL}:.*${ELK}"
        rm -f private_key.pem
        echo "SSH tunnel terminated"
      shell: bash 
























# name: Deploy ELK Stack

# on:
#   workflow_call:  # Only callable by other workflows
#     inputs:
#       log_file:
#         required: true
#          

# jobs:
#   elk-deploy:
#       runs-on: ubuntu-latest
#       steps:
#         # 1. Checkout Code from GitHub
#         - name: Checkout Code
#           uses: actions/checkout@v4

#         # 3. deploy elk
#         - name: Deploy and start elk stack
#           env:
#             USER: ${{  inputs.EC2_USER }}
#             TUNNEL: ${{  inputs.ELK_TUNNEL_PORT }}
#             LOGSTASH_PORT: ${{  inputs.LOGSTASH_PORT }}
#             ELASTICSEARCH_PORT: ${{  inputs.ELASTICSEARCH_PORT }}
#             PRIVATE_KEY: ${{  inputs.EC2_SSH_KEY }}
#              LOGS_SEPARATOR: "=================================================================================================================================================================================="
            
#           run: |
#             set -e
#             export LOGSTASH_PORT=${{  inputs.LOGSTASH_PORT }}
#             export ELASTICSEARCH_PORT=${{  inputs.ELASTICSEARCH_PORT }}
#             export LOGS_SEPARATOR=${LOGS_SEPARATOR}

#             echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

#             # SSH into the EC2 instance and install elk and start it
#             ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF' | tee ${{ inputs.log_file }}         
#               echo "${LOGS_SEPARATOR}"

#               # Update package index
#               echo "updating system"
#               sudo apt-get update -y && sudo apt-get upgrade -y

#               echo "Installing Java."
#               # Install Java (required by Elasticsearch)
#               echo "${LOGS_SEPARATOR}"
#               sudo apt-get install -y openjdk-11-jdk

#               echo "Installing Elasticsearch."
#               echo "${LOGS_SEPARATOR}"
#               if ! dpkg -s elasticsearch &>/dev/null; then
#                 wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
#                 sudo apt-get install apt-transport-https
#                 echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
#                 sudo apt-get update && sudo apt-get install elasticsearch
#                 sleep 15
#                 sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
#                 sudo /bin/systemctl daemon-reload
#                 sudo /bin/systemctl enable elasticsearch.service
#                 sleep 30
#                 sudo systemctl start elasticsearch.service
#                 sleep 30
                  
#                 echo "Generating the Elasticsearch password for the 'elastic' user."
#                 echo "${LOGS_SEPARATOR}"
#                 ELASTIC_PASSWORD=$(sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -b | awk '/New value:/ {print $NF}')
#                 sleep 15
#                 echo "$ELASTIC_PASSWORD" > elastic_password.txt
                
#                 echo "FILE_TRANSFER_START"
#                 base64 elastic_password.txt
#                 echo "FILE_TRANSFER_END"

#                 rm elastic_password.txt
                  
#               else
#                 echo "Elasticsearch already installed."
#                 sudo systemctl restart elasticsearch
#                 sleep 10
#               fi

#               echo "Installing Kibana."
#               echo "${LOGS_SEPARATOR}"
#               if ! dpkg -s kibana &>/dev/null; then
#                 sudo apt-get update && sudo apt-get install kibana
#                 sleep 10
#                 sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set server.basePath
#                 sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set server.rewriteBasePath
#                 sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && \
#                 echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

#                 # Set elasticsearch.hosts
#                 sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && \
#                 echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
                
#                 echo "${LOGS_SEPARATOR}"
#                 echo "seting enrolment token."
#                 TOKEN=$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
#                 sleep 20

#                 echo "${LOGS_SEPARATOR}"
#                 echo "applying token to kibana setup."
#                 sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "$TOKEN"

#                 sudo /bin/systemctl daemon-reload
#                 sudo /bin/systemctl enable kibana.service
#                 sleep 10
#                 sudo systemctl start kibana.service
#               else
#                 echo "Kibana already installed. Restarting..."
#                 sudo systemctl restart kibana
#               fi

#               echo "${LOGS_SEPARATOR}"
#               echo "Installing Logstash."
#               if ! dpkg -s logstash &>/dev/null; then
#                 echo "Installing Logstash..."
#                 sudo apt-get update -y && sudo apt-get install logstash
#                 sudo systemctl enable logstash.service  
#                 sudo systemctl start logstash.service

#                 echo "${LOGS_SEPARATOR}"
#                 echo "Configuring logstash"
#                 sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH_CONFIG
#                   input {
#                     beats {
#                       port => ${LOGSTASH_PORT}
#                     }
#                   }

#                   filter {
#                     grok {
#                       match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
#                     }
#                     date {
#                       match => ["timestamp", "ISO8601"]
#                     }
#                   }

#                   output {
#                     elasticsearch {
#                       hosts => ["https://localhost:${ELASTICSEARCH_PORT}"]
#                       index => "flask-logs-%{+YYYY.MM.dd}"
#                       user => "elastic"
#                       password => "${ELASTIC_PASSWORD}"
#                       ssl => true
#                       cacert => "/etc/elasticsearch/certs/http_ca.crt"
#                     }
#                   }
#             LOGSTASH_CONFIG
#               echo "restarting logstash"
#               sudo systemctl restart logstash

#               else
#                 echo "Logstash already installed."
#                 sudo systemctl restart logstash
#                 sleep 10
#               fi

#               checks
#               sudo systemctl status elasticsearch
#               sudo systemctl status logstash
#               sudo systemctl status kibana
#             EOF

#         - name: Encrypt and upload logs to s3
#           env:
#             AWS_ACCESS_KEY_ID: ${{  inputs.AWS_ACCESS_KEY_ID }}
#             AWS_SECRET_ACCESS_KEY: ${{  inputs.AWS_SECRET_ACCESS_KEY }}
#             AWS_REGION: ${{  inputs.AWS_REGION }}
#             GPG_PASSPHRASE: ${{  inputs.DEVSECOPS_GPG_PASSPHRASE }}
#              LOGS_SEPARATOR: "=================================================================================================================================================================================="
#           run: |
#             echo "${LOGS_SEPARATOR}"
#             echo "Extracting and encoding elasticsearch password from heredoc."
#             awk '/FILE_TRANSFER_START/{flag=1;next} /FILE_TRANSFER_END/{flag=0} flag' ${{ inputs.log_file }}  | base64 -d > elastic_password.txt
#             gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 elastic_password.txt
#             aws s3 cp elastic_password.txt.gpg s3://sedem-terra333-bucket/devsecops-jomacs/elastic_password.txt.gpg

#             echo "${LOGS_SEPARATOR}"
#             echo "Encrypting and uploading the log file using the GPG passphrase stored in GitHub  inputs.==="
#             gpg --batch --yes --passphrase "${GPG_PASSPHRASE}" --symmetric --cipher-algo AES256 ${{ inputs.log_file }} 
#             aws s3 cp ${{ inputs.log_file }}.gpg  s3://sedem-terra333-bucket/devsecops-jomacs/logs/${{ inputs.log_file }}.gpg

#             echo "${LOGS_SEPARATOR}"
#             echo "removing generated files"
#             rm ${{ inputs.log_file }} 
#             rm ${{ inputs.log_file }}.gpg
#             rm elastic_password.txt
#             rm elastic_password.txt.gpg
            
#         # 4. Clean-up tunnel
#         - name: Cleanup SSH Tunnel
#           if: always() # Runs even if previous steps fail
#           run: |
#             # Kill tunnel process using port ${TUNNEL}
#             pkill -f "ssh.*${TUNNEL}:.*${ELK}"
#             rm -f private_key.pem
#             echo "SSH tunnel terminated"