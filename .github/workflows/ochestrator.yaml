name: Full Infrastructure + App Deploy + ELK Deploy

on:
  workflow_dispatch:
    inputs:
      action:
        description: "apply/destroy"
        required: true
        default: "apply"
        type: choice
        options:
          - full-deploy
          - destroy
          - infra-only
          - scan-only
          - build-only
          - deploy-elk-only
          - scan+deploy-app-only
          - scan+deploy-app-only+deploy-elk-only
          - infra+scan+app
          - infra+scan+app+elk 
          - infra+elk
          - scan+build

jobs:
  terraform-apply:
    if: contains(fromJson('["infra-only", "infra+elk", "infra+scan+app+elk ", "infra+scan+app", "full-deploy"]'), github.event.inputs.action) #if: ${{ github.event.inputs.action == 'apply' }}
    name: "Terraform-apply"
    runs-on: ubuntu-latest
    outputs:
      bastion_ip: ${{ steps.tf_outputs.outputs.bastion_ip }}
      ec2_ip: ${{ steps.tf_outputs.outputs.ec2_ip }}
      elk_ip: ${{ steps.tf_outputs.outputs.elk_ip }}
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    defaults:
      run:
        working-directory: infra/aws/

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.1
          terraform_wrapper: false

      - name: Terraform Init
        run: terraform init

      - name: Terraform fmt
        run: terraform fmt -recursive

      - name: Terraform Plan
        run: terraform plan -no-color

      - name: Terraform Apply
        run: terraform apply -auto-approve

      - name: Capture Terraform Outputs
        id: tf_outputs
        run: |
          terraform output -json > outputs.json
          echo "Generated outputs.json at: $(pwd)/outputs.json"
              echo "--- outputs.json ---"
              cat outputs.json
              echo "--------------------"
          sudo apt-get install -y jq 
          echo "bastion_ip=$(jq -r '.bastion_public_ip.value' outputs.json)" >> $GITHUB_OUTPUT
          echo "ec2_ip=$(jq -r '.ec2_private_ip.value' outputs.json)" >> $GITHUB_OUTPUT
          echo "elk_ip=$(jq -r '.elk_private_ip.value' outputs.json)" >> $GITHUB_OUTPUT

      - name: Upload Terraform Outputs to Github Aretefacts
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: infra/aws/outputs.json

      - name: Upload Terraform outputs to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          aws s3 cp outputs.json s3://sedem-terra333-bucket/devsecops-jomacs/tf-outputs-latest.json

  scan:
    runs-on: ubuntu-latest
    if: contains(fromJson('["scan-only", "scan+build", "infra+scan+app", "infra+scan+app+elk", "scan+deploy-app-only", "scan+deploy-app-only+deploy-elk-only", "full-deploy"]'), github.event.inputs.action) #${{ github.event.inputs.action == 'apply' }}
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2

      # 2. Set up Python environment and install dependencies
      - name: Set up Python 3.x
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ./app/python/requirements.txt
          pip install bandit safety

      # 3. Run Bandit scan (Python code security scanner)
      - name: Run Bandit Scan
        run: |
          bandit -r ./app/python -f json -o app/python/bandit-report.json || exit 1

      # 4. Run Safety scan (Dependency vulnerability scanner)
      - name: Run Safety Scan
        run: |
          safety check -r app/python/requirements.txt --policy-file app/python/.safety.yaml --output json > app/python/safety-report.json || exit 1

      # 5. Upload the reports for later review
      - name: Upload Bandit Report
        if: always() # Always upload, even if workflow fails
        uses: actions/upload-artifact@v4
        with:
          name: bandit-report
          path: ./app/python/bandit-report.json

      - name: Upload Safety Report
        if: always() # Always upload, even if workflow fails
        uses: actions/upload-artifact@v4
        with:
          name: safety-report
          path: ./app/python/safety-report.json

  build:
    needs: scan # Ensure deploy only happens after the scan job
    if: contains(fromJson('["build-only", "scan+build", "full-deploy"]'), github.event.inputs.action) #if: ${{ github.event.inputs.action == 'apply' && success() }}
    runs-on: ubuntu-latest
    steps:
      #1. Checkout code from the repository
      - name: Checkout code
        uses: actions/checkout@v2

      #2. Set up Docker Buildx (required for multi-platform builds)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      #3. Set up Docker
      - name: Set up Docker
        uses: docker/setup-qemu-action@v2

      #4. Build the Docker image
      - name: Build Docker image
        run: |
          docker build -t michaelkedey/jomacsdevsecops:latest -f app/containerization/Dockerfile app/python/

      #5. Install Trivy
      - name: Install Trivy
        run: |
          curl -sfL https://github.com/aquasecurity/trivy/releases/download/v0.40.0/trivy_0.40.0_Linux-64bit.deb -o trivy.deb
          sudo dpkg -i trivy.deb

      #6. Scan the Docker image for vulnerabilities using Trivy
      - name: Scan Docker image for vulnerabilities
        id: trivy_scan
        run: |
          mkdir -p trivy-reports
          trivy image --no-progress --severity HIGH,CRITICAL --format json --output trivy-reports/scan-report.json michaelkedey/jomacsdevsecops:latest

      #7. Upload the Trivy scan report as an artifact (so you can download it later)
      - name: Upload Trivy scan report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-scan-report
          path: trivy-reports/scan-report.json

      #8. If no vulnerabilities with high severity are found, push to Docker Hub
      - name: Push Docker image to Docker Hub
        if: ${{ success() }}
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        run: |
          echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin
          docker push michaelkedey/jomacsdevsecops:latest

  deploy-app:
    needs: [terraform-apply, scan] # Ensure deploy only happens after the scan job
    if: contains(fromJson('["infra+scan+app", "infra+scan+app+elk ", "full-deploy"]'), github.event.inputs.action) #if: ${{ github.event.inputs.action == 'apply' && success() }}  # Only run if the scan job succeeds
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2

      # 2. Set up SSH key and establish SSH Tunnel
      - name: Set up SSH tunnel and deploy code
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          BASTION: ${{ needs.terraform-apply.outputs.bastion_ip }}
          HOST: ${{ needs.terraform-apply.outputs.ec2_ip }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}
        run: |
          echo "waiting for instances to be ready"
          sleep 60

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

          # Establish the SSH tunnel from GitHub Actions to the target EC2 instance
          # This command forwards the local port ${TUNNEL} to the target EC2 instance's SSH  
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${HOST}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f
      
      # 3. copy code and deploy
      - name: Deploy app and start Gunicorn
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}
          HOST: ${{ needs.terraform-apply.outputs.ec2_ip }}
          LOGSTASH_IP: ${{ needs.terraform-apply.outputs.elk_ip }}
          LOGSTASH_PORT: ${{ secrets.LOGSTASH_PORT }}
          APP_PORT: ${{ secrets.APP_PORT }}
        run: |
          rsync -avz -e "ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no" ./app/python/ ${USER}@localhost:/home/${USER}/my-app/

          # Export environment variables for the SSH session
          export LOGSTASH_IP="${LOGSTASH_IP}"
          export USER="${USER}"
          export LOGSTASH_PORT="${LOGSTASH_PORT}"
          export APP_PORT="${APP_PORT}"

          # SSH into the EC2 instance and install dependencies and start Gunicorn
          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << EOF
            # Install dependencies
            cd /home/${USER}/my-app/
            sudo apt-get update -y -y && sudo apt-get upgrade -y
            sudo apt-get install python3-pip -y
            sudo apt-get install gunicorn -y
            sudo apt-get install python3-flask -y
            pip install -r requirements.txt
            echo "Creating necessary log directories..."
            sudo mkdir -p logs
            sudo chown $USER:$USER logs
            echo "starting Gunicorn"
            nohup gunicorn -w 4 -b 127.0.0.1:${APP_PORT} app:app \
            > /home/$USER/my-app/logs/access.log 2> /home/$USER/my-app/logs/error.log &

            echo "Nginx Permissions"
            sudo chmod +x /home/${USER}
            sudo chmod +x /home/${USER}/my-app
            sudo chmod +x /home/${USER}/my-app/static

            echo "installing nginx for proxy ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q nginx.service; then
              sudo apt-get update -y && sudo apt-get upgrade -y
              sudo apt-get install nginx -y
              sudo systemctl enable nginx 
              sudo systemctl start nginx
            else 
              echo "Nginx is already installed"
              sudo systemctl restart nginx
            fi

            echo "Creating Nginx config for APP ================================================================================================================================="
            sudo rm /etc/nginx/sites-available/default
            sudo rm /etc/nginx/sites-enabled/default
            sudo tee /etc/nginx/sites-available/default > /dev/null << NGINX
            server {
              listen 80 default_server;
              server_name _;

              # Static files
              location /app/static/ {
                alias /home/ubuntu/my-app/static/;
                expires 30d;
                access_log off;
              }

              # Reverse proxy for Flask app
              location /app/ {
                proxy_pass http://127.0.0.1:\{APP_PORT}/;

                proxy_set_header Host \$host;
                proxy_set_header X-Real-IP \$remote_addr;
                proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto \$scheme;
              }
            }
      
          NGINX

            echo "Enabling Nginx site ================================================================================================================================="
            sudo ln -sf /etc/nginx/sites-available/default /etc/nginx/sites-enabled/
            sudo nginx -t
            sudo systemctl restart nginx
            sudo systemctl status nginx

            echo "install filebeat for logs ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q filebeat.service; then
              wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
              sudo apt-get install apt-transport-https
              # Add Elastic 8.x APT repo
              echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
              sudo apt-get update && sudo apt-get install filebeat
              sudo systemctl enable filebeat
              sudo systemctl start filebeat
            else 
              echo "Filebeat is already installed"
              sudo systemctl restart filebeat
            fi

            echo "Configuring Filebeat to read logs...================================================================================================================================="
            sudo tee /etc/filebeat/filebeat.yml > /dev/null << FILEBEAT
            filebeat.inputs:
              - type: log
                enabled: true
                paths:
                  - /home/${USER}/my-app/logs/access.log
                  - /home/${USER}/my-app/logs/error.log
                fields:
                  app: my-flask-app
                fields_under_root: true

            output.logstash:
              hosts: ["http://${LOGSTASH_IP}:${LOGSTASH_PORT}"] 
          FILEBEAT

          echo "restarting filebeat"
          sudo systemctl restart filebeat

          sudo systemctl status filebeat
          sudo systemctl status nginx

          EOF

        # 4. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always() # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${HOST}"
          rm -f private_key.pem
          echo "SSH tunnel terminated"

  deploy-app-only:
    needs: scan
    if: contains(fromJson('["scan+deploy-app-only", "scan+deploy-app-only+deploy-elk-only"]'), github.event.inputs.action)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v2

      - name: Download Terraform outputs from S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          mkdir -p terraform-outputs
          aws s3 cp s3://sedem-terra333-bucket/devsecops-jomacs/tf-outputs-latest.json terraform-outputs/outputs.json

      - name: Parse Terraform Outputs and establish SSH tunnel
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}
        run: |
          set -e
          sudo apt-get update && sudo apt-get install -y jq
          cat terraform-outputs/outputs.json

          bastion_ip=$(jq -r '.bastion_public_ip.value' terraform-outputs/outputs.json)
          BASTION=${bastion_ip}
          #echo "BASTION=${bastion_ip}" >> $GITHUB_ENV

          ec2_ip=$(jq -r '.ec2_private_ip.value' terraform-outputs/outputs.json)
          HOST=${ec2_ip}
          #echo "HOST=${ec2_ip}" >> $GITHUB_ENV

          elk_ip=$(jq -r '.elk_private_ip.value' terraform-outputs/outputs.json)
          #LOGSTASH_IP=${elk_ip}
          echo "LOGSTASH_IP=${elk_ip}" >> $GITHUB_ENV

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

          echo "Establishing SSH tunnel..."
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${HOST}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f

      - name: Deploy app and start Gunicorn
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.SSH_TUNNEL_PORT }}
          LOGSTASH_IP: ${{ env.LOGSTASH_IP }}
          LOGSTASH_PORT: ${{ secrets.LOGSTASH_PORT }}
          APP_PORT: ${{ secrets.APP_PORT }}
        run: |
          set -e

          rsync -avz -e "ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no" ./app/python/ ${USER}@localhost:/home/${USER}/my-app/

          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << EOF
            export LOGSTASH_IP="${LOGSTASH_IP}"
            export LOGSTASH_PORT="${LOGSTASH_PORT}"
            export APP_PORT="${APP_PORT}"

            # Install dependencies
            cd /home/${USER}/my-app/
            sudo apt-get update -y -y && sudo apt-get upgrade -y
            sudo apt-get install python3-pip -y
            sudo apt-get install gunicorn -y
            sudo apt-get install python3-flask -y
            pip install -r requirements.txt
            echo "Creating necessary log directories..."
            sudo mkdir -p logs
            sudo chown $USER:$USER logs
            echo "starting Gunicorn"
            nohup gunicorn -w 4 -b 127.0.0.1:${APP_PORT} app:app \
            > /home/$USER/my-app/logs/access.log 2> /home/$USER/my-app/logs/error.log &

            echo "Nginx Permissions"
            sudo chmod +x /home/${USER}
            sudo chmod +x /home/${USER}/my-app
            sudo chmod +x /home/${USER}/my-app/static

            echo "installing nginx for proxy ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q nginx.service; then
              sudo apt-get update -y && sudo apt-get upgrade -y
              sudo apt-get install nginx -y
              sudo systemctl enable nginx 
              sudo systemctl start nginx
            else 
              echo "Nginx is already installed"
              sudo systemctl restart nginx
            fi

            echo "Creating Nginx config for APP ================================================================================================================================="
            sudo rm /etc/nginx/sites-available/default
            sudo rm /etc/nginx/sites-enabled/default
            sudo tee /etc/nginx/sites-available/default > /dev/null << 'NGINX'
            server {
              listen 80 default_server;
              server_name _;

              # Static files
              location /app/static/ {
                alias /home/ubuntu/my-app/static/;
                expires 30d;
                access_log off;
              }

              # Reverse proxy for Flask app
              location /app/ {
                proxy_pass http://127.0.0.1:5000/;

                proxy_set_header Host \$host;
                proxy_set_header X-Real-IP \$remote_addr;
                proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto \$scheme;
              }
            }
      
          NGINX

            echo "Enabling Nginx site ================================================================================================================================="
            sudo ln -sf /etc/nginx/sites-available/default /etc/nginx/sites-enabled/
            sudo nginx -t
            sudo systemctl restart nginx
            sudo systemctl status nginx

            echo "install filebeat for logs ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q filebeat.service; then
              wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
              sudo apt-get install apt-transport-https
              # Add Elastic 8.x APT repo
              echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
              sudo apt-get update && sudo apt-get install filebeat
              sudo systemctl enable filebeat
              sudo systemctl start filebeat
            else 
              echo "Filebeat is already installed"
              sudo systemctl restart filebeat
            fi

            echo "Configuring Filebeat to read logs...================================================================================================================================="
            sudo tee /etc/filebeat/filebeat.yml > /dev/null << FILEBEAT
            filebeat.inputs:
              - type: log
                enabled: true
                paths:
                  - /home/${USER}/my-app/logs/access.log
                  - /home/${USER}/my-app/logs/error.log
                fields:
                  app: my-flask-app
                fields_under_root: true

            output.logstash:
              hosts: ["http://${LOGSTASH_IP}:${LOGSTASH_PORT}"] 
          FILEBEAT

          echo "restarting filebeat"
          sudo systemctl restart filebeat

          sudo systemctl status filebeat
          sudo systemctl status nginx

          EOF

        # 4. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always() # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${HOST}"
          rm -f private_key.pem
          echo "SSH tunnel terminated"

  deploy-elk:
    needs: terraform-apply # Ensure deploy only happens after the scan job
    if: contains(fromJson('["infra+elk", "infra+scan+app+elk", "full-deploy"]'), github.event.inputs.action) #if: ${{ github.event.inputs.action == 'apply' && success() }}  # Only run if the app deploy job succeeds
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2
      # 2. Set up SSH key and establish SSH Tunnel
      - name: Set up SSH tunnel and deploy code
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          BASTION: ${{ needs.terraform-apply.outputs.bastion_ip }}
          ELK: ${{ needs.terraform-apply.outputs.elk_ip }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
        run: |
          echo "waiting for instances to be ready"
          sleep 60

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

          # Establish the SSH tunnel from GitHub Actions to the target EC2 instance
          # This command forwards the local port ${TUNNEL} to the target EC2 instance's SSH  
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${ELK}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f
      # 3. deploy elk
      - name: Deploy and start elk stack
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
          PASSWORD: ${{ secrets.KIBANA_PASSWORD }}
          ELK: ${{ needs.terraform-apply.outputs.elk_ip }}
          LOGSTASH_PORT: ${{ secrets.LOGSTASH_PORT }}
          ELASTICSEARCH_PORT: ${{ secrets.ELASTICSEARCH_PORT }}
        run: |
          export LOGSTASH_PORT=${{ secrets.LOGSTASH_PORT }}
          export ELASTICSEARCH_PORT=${{ secrets.ELASTICSEARCH_PORT }}

          # SSH into the EC2 instance and install elk and start it
          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF'          
            # Update package index
            sudo apt-get update -y -y && sudo apt-get upgrade -y

            echo "Installing Java ================================================================================================================================="
            # Install Java (required by Elasticsearch)
            sudo apt-get install -y openjdk-11-jdk

            echo "Installing Elasticsearch ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q elasticsearch.service; then
              wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
              sudo apt-get install apt-transport-https
              echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
              sudo apt-get update && sudo apt-get install elasticsearch
              sleep 15
              sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo /bin/systemctl daemon-reload
              sudo /bin/systemctl enable elasticsearch.service
              sleep 30
              sudo systemctl start elasticsearch.service
              sleep 30
            else
              echo "Elasticsearch already installed."
              sudo systemctl restart elasticsearch
              sleep 10
            fi

            echo "Installing Kibana ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q kibana.service; then
              sudo apt-get update && sudo apt-get install kibana
              sleep 10
              sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && \
              echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set server.basePath
              sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && \
              echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set server.rewriteBasePath
              sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && \
              echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set elasticsearch.hosts
              sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && \
              echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
              
              echo "seting enrolment token ======================================================================================================================================="
              TOKEN=$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
              sleep 20
              echo "applying token to kibana setup ======================================================================================================================================="
              sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "$TOKEN"

              sudo /bin/systemctl daemon-reload
              sudo /bin/systemctl enable kibana.service
              sleep 10
              sudo systemctl start kibana.service
            else
              echo "Kibana already installed. Restarting..."
              sudo systemctl restart kibana
            fi

            
            echo "Installing Logstash ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q logstash.service; then
              echo "Installing Logstash..."
              sudo apt-get update -y && sudo apt-get install logstash
              sudo systemctl enable logstash.service  
              sudo systemctl start logstash.service
            else
              echo "Logstash already installed."
              sudo systemctl restart logstash
              sleep 10
            fi

            echo "Configuring logstash"
              sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH_CONFIG
                input {
                  beats {
                    port => ${LOGSTASH_PORT}
                  }
                }

                filter {
                  grok {
                    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
                  }
                  date {
                    match => ["timestamp", "ISO8601"]
                  }
                }

                output {
                  elasticsearch {
                    hosts => ["http://localhost:${ELASTICSEARCH_PORT}"]
                    index => "flask-logs-%{+YYYY.MM.dd}"
                  }
                }
          LOGSTASH_CONFIG
            echo "restarting logstash"
            sudo systemctl restart logstash

            checks
            sudo systemctl status elasticsearch
            sudo systemctl status logstash
            sudo systemctl status kibana

          EOF

      # 4. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always() # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${ELK}"
          rm -f private_key.pem
          echo "SSH tunnel terminated"


  deploy-elk-only:
    if: contains(fromJson('["deploy-elk-only", "scan+deploy-app-only+deploy-elk-only"]'), github.event.inputs.action) #if: ${{ github.event.inputs.action == 'apply' && success() }}  # Only run if the app deploy job succeeds
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout Code from GitHub
      - name: Checkout Code
        uses: actions/checkout@v2

      - name: Download Terraform outputs from S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          mkdir -p terraform-outputs
          aws s3 cp s3://sedem-terra333-bucket/devsecops-jomacs/tf-outputs-latest.json terraform-outputs/outputs.json
      
      - name: Parse Terraform Outputs and establish SSH tunnel
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          USER: ${{ secrets.EC2_USER }}
          PORT: ${{ secrets.SSH_PORT }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
        run: |
          set -e
          sudo apt-get update && sudo apt-get install -y jq
          cat terraform-outputs/outputs.json

          bastion_ip=$(jq -r '.bastion_public_ip.value' terraform-outputs/outputs.json)
          BASTION=${bastion_ip}
          #echo "BASTION=${bastion_ip}" >> $GITHUB_ENV

          elk_ip=$(jq -r '.elk_private_ip.value' terraform-outputs/outputs.json)
          ELK=${elk_ip}
          #echo "HOST=${elk_ip}" >> $GITHUB_ENV

          echo "$PRIVATE_KEY" > private_key.pem && chmod 600 private_key.pem

          # Establish the SSH tunnel from GitHub Actions to the target EC2 instance
          # This command forwards the local port ${TUNNEL} to the target EC2 instance's SSH  
          ssh -i private_key.pem -o StrictHostKeyChecking=no -tt -L ${TUNNEL}:${ELK}:${PORT} -p ${PORT} ${USER}@${BASTION} -N -f
      # 3. deploy elk
      - name: Deploy and start elk stack
        env:
          USER: ${{ secrets.EC2_USER }}
          TUNNEL: ${{ secrets.ELK_TUNNEL_PORT }}
          LOGSTASH_PORT: ${{ secrets.LOGSTASH_PORT }}
          ELASTICSEARCH_PORT: ${{ secrets.ELASTICSEARCH_PORT }}
        run: |
          export LOGSTASH_PORT=${{ secrets.LOGSTASH_PORT }}
          export ELASTICSEARCH_PORT=${{ secrets.ELASTICSEARCH_PORT }}

          # SSH into the EC2 instance and install elk and start it
          ssh -i private_key.pem -p ${TUNNEL} -o StrictHostKeyChecking=no ${USER}@localhost << 'EOF'          
            # Update package index
            sudo apt-get update -y -y && sudo apt-get upgrade -y

            echo "Installing Java ================================================================================================================================="
            # Install Java (required by Elasticsearch)
            sudo apt-get install -y openjdk-11-jdk

            echo "Installing Elasticsearch ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q elasticsearch.service; then
              wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
              sudo apt-get install apt-transport-https
              echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/9.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-9.x.list
              sudo apt-get update && sudo apt-get install elasticsearch
              sleep 15
              sudo sed -i '/^#\?cluster\.name:/d' /etc/elasticsearch/elasticsearch.yml && echo 'cluster.name: "elk"' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo sed -i '/^#\?network\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'network.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo sed -i '/^#\?transport\.host:/d' /etc/elasticsearch/elasticsearch.yml && echo 'transport.host: 0.0.0.0' | sudo tee -a /etc/elasticsearch/elasticsearch.yml > /dev/null
              sudo /bin/systemctl daemon-reload
              sudo /bin/systemctl enable elasticsearch.service
              sleep 30
              sudo systemctl start elasticsearch.service
              sleep 30
            else
              echo "Elasticsearch already installed."
              sudo systemctl restart elasticsearch
              sleep 10
            fi

            echo "Installing Kibana ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q kibana.service; then
              sudo apt-get update && sudo apt-get install kibana
              sleep 10
              sudo sed -i '/^#\?server\.host:/d' /etc/kibana/kibana.yml && \
              echo 'server.host: "0.0.0.0"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set server.basePath
              sudo sed -i '/^#\?server\.basePath:/d' /etc/kibana/kibana.yml && \
              echo 'server.basePath: "/elk"' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set server.rewriteBasePath
              sudo sed -i '/^#\?server\.rewriteBasePath:/d' /etc/kibana/kibana.yml && \
              echo 'server.rewriteBasePath: true' | sudo tee -a /etc/kibana/kibana.yml > /dev/null

              # Set elasticsearch.hosts
              sudo sed -i '/^#\?elasticsearch\.hosts:/d' /etc/kibana/kibana.yml && \
              echo 'elasticsearch.hosts: ["https://localhost:9200"]' | sudo tee -a /etc/kibana/kibana.yml > /dev/null
              
              echo "seting enrolment token ======================================================================================================================================="
              TOKEN=$(sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana)
              sleep 20
              echo "applying token to kibana setup ======================================================================================================================================="
              sudo /usr/share/kibana/bin/kibana-setup --enrollment-token "$TOKEN"

              sudo /bin/systemctl daemon-reload
              sudo /bin/systemctl enable kibana.service
              sleep 10
              sudo systemctl start kibana.service
            else
              echo "Kibana already installed. Restarting..."
              sudo systemctl restart kibana
            fi

            
            echo "Installing Logstash ================================================================================================================================="
            if ! systemctl list-units --type=service --all | grep -q logstash.service; then
              echo "Installing Logstash..."
              sudo apt-get update -y && sudo apt-get install logstash
              sudo systemctl enable logstash.service  
              sudo systemctl start logstash.service
            else
              echo "Logstash already installed."
              sudo systemctl restart logstash
              sleep 10
            fi

            echo "Configuring logstash"
              sudo tee /etc/logstash/conf.d/filebeat-to-es.conf > /dev/null << LOGSTASH_CONFIG
                input {
                  beats {
                    port => ${LOGSTASH_PORT}
                  }
                }

                filter {
                  grok {
                    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}: %{GREEDYDATA:msg}" }
                  }
                  date {
                    match => ["timestamp", "ISO8601"]
                  }
                }

                output {
                  elasticsearch {
                    hosts => ["http://localhost:${ELASTICSEARCH_PORT}"]
                    index => "flask-logs-%{+YYYY.MM.dd}"
                  }
                }
          LOGSTASH_CONFIG
            echo "restarting logstash"
            sudo systemctl restart logstash

            checks
            sudo systemctl status elasticsearch
            sudo systemctl status logstash
            sudo systemctl status kibana

          EOF

      # 4. Clean-up tunnel
      - name: Cleanup SSH Tunnel
        if: always() # Runs even if previous steps fail
        run: |
          # Kill tunnel process using port ${TUNNEL}
          pkill -f "ssh.*${TUNNEL}:.*${ELK}"
          rm -f private_key.pem
          echo "SSH tunnel terminated"

  terraform-destroy:
    name: "Terraform Destroy"
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    defaults:
      run:
        working-directory: infra/aws/
    # Only run if "destroy" is selected manually
    if: github.event.inputs.action == 'destroy'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.1

      - name: Terraform Init
        run: terraform init

      - name: Terraform Destroy
        run: terraform destroy -auto-approve
